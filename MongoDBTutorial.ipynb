{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to MongoDB with PyMongo and NOAA Data\n",
    "\n",
    "This notebook provides a basic walkthrough of how to use MongoDB and is based on a tutorial originally by [Alberto Negron](http://altons.github.io/python/2013/01/21/gentle-introduction-to-mongodb-using-pymongo/).\n",
    "\n",
    "Metadata records are frequently stored as JSON, and almost anything you get from an API will be JSON. For example, check out the [metadata records](https://data.noaa.gov/data.json) for the National Oceanic and Atmospheric Administration. \n",
    "\n",
    "MongoDB is a great tool to use with JSON data because it stores structured data as JSON-like documents, using dynamic schemas (called BSON), rather than predefined schemas. \n",
    "\n",
    "In MongoDB, an element of data is called a document, and documents are stored in collections. One collection may have any number of documents. Collections are a bit like tables in a relational database, and documents are like records. But there is one big difference: every record in a table has the same fields (with, usually, differing values) in the same order, while each document in a collection can have completely different fields from the other documents.\n",
    "\n",
    "Documents are Python dictionaries that can have strings as keys and can contain various primitive types (int, float,unicode, datetime) as well as other documents (Python dicts) and arrays (Python lists).\n",
    "\n",
    "## Getting started\n",
    "First we need to import `json` and `pymongo`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pymongo\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect    \n",
    "Just as with the relational database example with `sqlite`, we need to begin by setting up a connection. With MongoDB, we will be using `pymongo`, though MongoDB also comes with a [console API that uses Javascript](https://docs.mongodb.org/manual/tutorial/write-scripts-for-the-mongo-shell/).    \n",
    "\n",
    "\n",
    "To make our connection, we will use the PyMongo method `MongoClient`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn=pymongo.MongoClient()\n",
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and access a database    \n",
    "Mongodb creates databases and collections automatically for you if they don't exist already. A single instance of MongoDB can support multiple independent databases. When working with PyMongo, we access databases using attribute style access, just like we did with `sqlite`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'mydb')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = conn.mydb\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collections    \n",
    "A collection is a group of documents stored in MongoDB, and can be thought of as roughly the equivalent of a table in a relational database. Getting a collection in PyMongo works the same as getting a database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'mydb'), u'my_collection')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = db.my_collection\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert data   \n",
    "To insert some data into MongoDB, all we need to do is create a dict and call `insert_one` on the collection object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x104c7f0a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = {\"class\":\"XBUS-502\",\"date\":\"03-05-2016\",\"instructor\":\"Bengfort\",\"classroom\":\"C222\",\"roster_count\":\"25\"}\n",
    "collection.insert_one(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'local', u'mydb']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'my_collection', u'system.indexes']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A practical example\n",
    "\n",
    "Let's say you wanted to gather up a bunch of JSON metadata records and store them for analysis. \n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "NOAA_URL = \"https://data.noaa.gov/data.json\"\n",
    "\n",
    "def load_data(URL):\n",
    "    \"\"\"\n",
    "    Loads the data from URL and returns data in JSON format.\n",
    "    \"\"\"\n",
    "    r = requests.get(URL)\n",
    "    data = r.json()\n",
    "    return data\n",
    "    \n",
    "noaa = load_data(NOAA_URL)\n",
    "```\n",
    "\n",
    "This takes a long time, so I've created a file for you that contains a small chunch of the records to use for today's workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"data_sample.json\") as data_file:    \n",
    "    noaa = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1722"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noaa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking out the data\n",
    "Now let's print out just one record to examine the structure. Note that the `pprint` module provides a capability to “pretty-print” arbitrary Python data structures in a form which can be used as input to the interpreter. This is particularly helpful with JSON. You can read more about `pprint` [here](https://docs.python.org/2/library/pprint.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u\"This data set contains sea ice and snow measurements collected during aircraft landings associated with the Soviet Union's historical Sever airborne and North Pole drifting station programs. The High-Latitude Airborne Annual Expeditions Sever (Sever means North) took place in 1937, 1941, 1948-1952, and 1954-1993 (Konstantinov and Grachev, 2000). In Spring 1993, the last (45th) Sever expedition finished long-term activity in the Arctic. Snow and sea ice data were collected, along with meteorological and hydrological measurements (the latter are not part of this data set). Up to 202 landings were accomplished each year.  The data set contains measurements of 23 parameters, including ice thickness and snow depth on the runway and surrounding area; ridge, hummock, and sastrugi dimensions and areal coverage; and snow density. The sea ice thickness data are of particular importance, as ice thickness measurements for the Arctic Basin are scarce. These data are a subset of those used to create the atlas Morphometric Characteristics of Ice and Snow in the Arctic Basin, self-published by Ilya P. Romanov in 1993, and republished by Backbone Publishing Company in 1995. Romanov provided these data to the National Snow and Ice Data Center (NSIDC) in 1994.\"\n"
     ]
    }
   ],
   "source": [
    "pprint(noaa[0]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the database\n",
    "We will want to enter these records into our database. But first, we'll define a specific database for the NOAA records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = conn.earthwindfire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the collection\n",
    "Next we define the collection where we'll insert the NOAA metadata records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records = db.records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert data    \n",
    "Then we loop through each record in the NOAA dataset and insert just the target information for each into the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def insert(metadata):\n",
    "    for dataset in metadata:\n",
    "        data ={}\n",
    "        data[\"title\"] = dataset[\"title\"]\n",
    "        data[\"description\"] = dataset[\"description\"]\n",
    "        data[\"keywords\"] = dataset[\"keyword\"]\n",
    "        data[\"accessLevel\"] = dataset[\"accessLevel\"]\n",
    "        # choose your own\n",
    "        # choose your own\n",
    "        # choose your own \n",
    "        # choose your own\n",
    "\n",
    "        records.insert_one(data)\n",
    "\n",
    "insert(noaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1722"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying \n",
    "\n",
    "#### Querying with `.findOne( )`    \n",
    "The find_one() method selects and returns a single document from a collection and returns that document (or None if there are no matches). It is useful when you know there is only one matching document, or are only interested in the first match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('56d8326bbe18b11696b601df'),\n",
       " u'accessLevel': u'public',\n",
       " u'description': u\"This data set contains sea ice and snow measurements collected during aircraft landings associated with the Soviet Union's historical Sever airborne and North Pole drifting station programs. The High-Latitude Airborne Annual Expeditions Sever (Sever means North) took place in 1937, 1941, 1948-1952, and 1954-1993 (Konstantinov and Grachev, 2000). In Spring 1993, the last (45th) Sever expedition finished long-term activity in the Arctic. Snow and sea ice data were collected, along with meteorological and hydrological measurements (the latter are not part of this data set). Up to 202 landings were accomplished each year.  The data set contains measurements of 23 parameters, including ice thickness and snow depth on the runway and surrounding area; ridge, hummock, and sastrugi dimensions and areal coverage; and snow density. The sea ice thickness data are of particular importance, as ice thickness measurements for the Arctic Basin are scarce. These data are a subset of those used to create the atlas Morphometric Characteristics of Ice and Snow in the Arctic Basin, self-published by Ilya P. Romanov in 1993, and republished by Backbone Publishing Company in 1995. Romanov provided these data to the National Snow and Ice Data Center (NSIDC) in 1994.\",\n",
       " u'keywords': [u'Continent > Europe > Eastern Europe > Russia',\n",
       "  u'Geographic Region > Arctic > Arctic Basin',\n",
       "  u'EARTH SCIENCE > Cryosphere > Sea Ice > Ice Deformation',\n",
       "  u'EARTH SCIENCE > Cryosphere > Sea Ice > Ice Depth/Thickness',\n",
       "  u'EARTH SCIENCE > Cryosphere > Sea Ice > Ice Floes > Length',\n",
       "  u'EARTH SCIENCE > Cryosphere > Sea Ice > Ice Floes > Width',\n",
       "  u'EARTH SCIENCE > Cryosphere > Sea Ice > Ice Roughness > Hummocks',\n",
       "  u'EARTH SCIENCE > Cryosphere > Sea Ice > Sea Ice Elevation > Hummocks',\n",
       "  u'EARTH SCIENCE > Cryosphere > Sea Ice > Snow Depth',\n",
       "  u'EARTH SCIENCE > Cryosphere > Snow/Ice > Snow Density',\n",
       "  u'EARTH SCIENCE > Cryosphere > Snow/Ice > Snow Depth',\n",
       "  u'EARTH SCIENCE > Oceans > Sea Ice > Ice Deformation',\n",
       "  u'EARTH SCIENCE > Oceans > Sea Ice > Ice Depth/Thickness',\n",
       "  u'EARTH SCIENCE > Oceans > Sea Ice > Ice Floes > Length',\n",
       "  u'EARTH SCIENCE > Oceans > Sea Ice > Ice Floes > Width',\n",
       "  u'EARTH SCIENCE > Oceans > Sea Ice > Ice Roughness > Hummocks',\n",
       "  u'EARTH SCIENCE > Oceans > Sea Ice > Sea Ice Elevation',\n",
       "  u'EARTH SCIENCE > Oceans > Sea Ice > Snow Depth',\n",
       "  u'EARTH SCIENCE > Terrestrial Hydrosphere > Snow/Ice > Snow Density',\n",
       "  u'EARTH SCIENCE > Terrestrial Hydrosphere > Snow/Ice > Snow Depth',\n",
       "  u'Aircraft',\n",
       "  u'Arctic Basin',\n",
       "  u'Arctic Sea Ice',\n",
       "  u'g02140',\n",
       "  u'NOAA',\n",
       "  u'North Pole',\n",
       "  u'North Pole drifting station',\n",
       "  u'Sever'],\n",
       " u'title': u'Morphometric Characteristics of Ice and Snow in the Arctic Basin: Aircraft Landing Observations from the Former Soviet Union, 1928-1989'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying with `.find( )`\n",
    "To get more than a single document as the result of a query we use the `find()` method. `find()` returns a Cursor instance, which allows us to iterate over all matching documents.\n",
    "\n",
    "```python\n",
    "records.find()\n",
    "```\n",
    "\n",
    "For example, we can iterate over the first 2 documents (there are a lot in the collection and this is just an example) in the records collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('56d8326bbe18b11696b601df'),\n",
      " u'accessLevel': u'public',\n",
      " u'description': u\"This data set contains sea ice and snow measurements collected during aircraft landings associated with the Soviet Union's historical Sever airborne and North Pole drifting station programs. The High-Latitude Airborne Annual Expeditions Sever (Sever means North) took place in 1937, 1941, 1948-1952, and 1954-1993 (Konstantinov and Grachev, 2000). In Spring 1993, the last (45th) Sever expedition finished long-term activity in the Arctic. Snow and sea ice data were collected, along with meteorological and hydrological measurements (the latter are not part of this data set). Up to 202 landings were accomplished each year.  The data set contains measurements of 23 parameters, including ice thickness and snow depth on the runway and surrounding area; ridge, hummock, and sastrugi dimensions and areal coverage; and snow density. The sea ice thickness data are of particular importance, as ice thickness measurements for the Arctic Basin are scarce. These data are a subset of those used to create the atlas Morphometric Characteristics of Ice and Snow in the Arctic Basin, self-published by Ilya P. Romanov in 1993, and republished by Backbone Publishing Company in 1995. Romanov provided these data to the National Snow and Ice Data Center (NSIDC) in 1994.\",\n",
      " u'keywords': [u'Continent > Europe > Eastern Europe > Russia',\n",
      "               u'Geographic Region > Arctic > Arctic Basin',\n",
      "               u'EARTH SCIENCE > Cryosphere > Sea Ice > Ice Deformation',\n",
      "               u'EARTH SCIENCE > Cryosphere > Sea Ice > Ice Depth/Thickness',\n",
      "               u'EARTH SCIENCE > Cryosphere > Sea Ice > Ice Floes > Length',\n",
      "               u'EARTH SCIENCE > Cryosphere > Sea Ice > Ice Floes > Width',\n",
      "               u'EARTH SCIENCE > Cryosphere > Sea Ice > Ice Roughness > Hummocks',\n",
      "               u'EARTH SCIENCE > Cryosphere > Sea Ice > Sea Ice Elevation > Hummocks',\n",
      "               u'EARTH SCIENCE > Cryosphere > Sea Ice > Snow Depth',\n",
      "               u'EARTH SCIENCE > Cryosphere > Snow/Ice > Snow Density',\n",
      "               u'EARTH SCIENCE > Cryosphere > Snow/Ice > Snow Depth',\n",
      "               u'EARTH SCIENCE > Oceans > Sea Ice > Ice Deformation',\n",
      "               u'EARTH SCIENCE > Oceans > Sea Ice > Ice Depth/Thickness',\n",
      "               u'EARTH SCIENCE > Oceans > Sea Ice > Ice Floes > Length',\n",
      "               u'EARTH SCIENCE > Oceans > Sea Ice > Ice Floes > Width',\n",
      "               u'EARTH SCIENCE > Oceans > Sea Ice > Ice Roughness > Hummocks',\n",
      "               u'EARTH SCIENCE > Oceans > Sea Ice > Sea Ice Elevation',\n",
      "               u'EARTH SCIENCE > Oceans > Sea Ice > Snow Depth',\n",
      "               u'EARTH SCIENCE > Terrestrial Hydrosphere > Snow/Ice > Snow Density',\n",
      "               u'EARTH SCIENCE > Terrestrial Hydrosphere > Snow/Ice > Snow Depth',\n",
      "               u'Aircraft',\n",
      "               u'Arctic Basin',\n",
      "               u'Arctic Sea Ice',\n",
      "               u'g02140',\n",
      "               u'NOAA',\n",
      "               u'North Pole',\n",
      "               u'North Pole drifting station',\n",
      "               u'Sever'],\n",
      " u'title': u'Morphometric Characteristics of Ice and Snow in the Arctic Basin: Aircraft Landing Observations from the Former Soviet Union, 1928-1989'}\n",
      "{u'_id': ObjectId('56d8326cbe18b11696b601e0'),\n",
      " u'accessLevel': u'public',\n",
      " u'description': u'This data set was distributed by NSIDC until October, 2003, when it was withdrawn from distribution because it duplicates the NOAA National Climatic Data Center (NCDC) data set DSI-3720. The NCDC data set is revised and updated beyond what was distributed by NSIDC. This archive consists of monthly precipitation measurements from 622 stations located in the Former Soviet Union.',\n",
      " u'keywords': [u'Continent > Europe > Eastern Europe > Russia',\n",
      "               u'EARTH SCIENCE > Atmosphere > Precipitation > Precipitation Amount',\n",
      "               u'EARTH SCIENCE > Atmosphere > Precipitation > Precipitation Rate',\n",
      "               u'EARTH SCIENCE > Atmosphere > Precipitation > Rain',\n",
      "               u'EARTH SCIENCE > Atmosphere > Precipitation > Snow',\n",
      "               u'EARTH SCIENCE > Terrestrial Hydrosphere > Snow/Ice > Snow Cover',\n",
      "               u'EOSDIS > Earth Observing System Data Information System',\n",
      "               u'ESIP > Earth Science Information Partners Program',\n",
      "               u'Asia',\n",
      "               u'Europe',\n",
      "               u'Former Soviet Union',\n",
      "               u'GAUGE BUCKET',\n",
      "               u'GAUGE POST',\n",
      "               u'NIPHER',\n",
      "               u'Precipitation',\n",
      "               u'Rain',\n",
      "               u'Rain Gauge',\n",
      "               u'Russia',\n",
      "               u'Soviet',\n",
      "               u'State Hydrological Institute',\n",
      "               u'Station',\n",
      "               u'Tretiyakov',\n",
      "               u'Ussr'],\n",
      " u'title': u'Former Soviet Union Monthly Precipitation Archive, 1891-1993'}\n"
     ]
    }
   ],
   "source": [
    "for rec in records.find()[:2]:\n",
    "    pprint(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching \n",
    "MongoDB queries are represented as JSON-like structure, just like documents. To build a query, you just need to specify a dictionary with the properties you wish the results to match. For example, let's say we were just interested in publically available satellite data from [NESDIS](http://www.nesdis.noaa.gov/).\n",
    "\n",
    "This query will match all documents in the records collection with keywords code \"NESDIS\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1117"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.find({\"keywords\": \"NESDIS\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further narrow our search by adding additional fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.find({\"keywords\": \"NESDIS\",\"keywords\": \"Russia\",\"accessLevel\":\"public\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'avgObjSize': 2235.0869061413673,\n",
       " u'collections': 3,\n",
       " u'dataFileVersion': {u'major': 4, u'minor': 22},\n",
       " u'dataSize': 3857760.0,\n",
       " u'db': u'earthwindfire',\n",
       " u'extentFreeList': {u'num': 0, u'totalSize': 0},\n",
       " u'fileSize': 67108864.0,\n",
       " u'indexSize': 65408.0,\n",
       " u'indexes': 1,\n",
       " u'nsSizeMB': 16,\n",
       " u'numExtents': 8,\n",
       " u'objects': 1726,\n",
       " u'ok': 1.0,\n",
       " u'storageSize': 11194368.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.command({'dbstats': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'avgObjSize': 2240,\n",
       " u'capped': False,\n",
       " u'count': 1722,\n",
       " u'indexDetails': {},\n",
       " u'indexSizes': {u'_id_': 65408},\n",
       " u'lastExtentSize': 8388608.0,\n",
       " u'nindexes': 1,\n",
       " u'ns': u'earthwindfire.records',\n",
       " u'numExtents': 6,\n",
       " u'ok': 1.0,\n",
       " u'paddingFactor': 1.0,\n",
       " u'paddingFactorNote': u'paddingFactor is unused and unmaintained in 3.0. It remains hard coded to 1.0 for compatibility only.',\n",
       " u'size': 3857504,\n",
       " u'storageSize': 11182080,\n",
       " u'totalIndexSize': 65408,\n",
       " u'userFlags': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.command({'collstats': 'records'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The aggregation pipeline \n",
    "\n",
    "The aggregation pipeline allows MongoDB to provide native aggregation capabilities that corresponds to many common data aggregation operations in SQL.\n",
    "\n",
    "The following table provides an overview of common SQL aggregation terms, functions, and concepts and the corresponding MongoDB aggregation operators:    \n",
    "    \n",
    "| SQL Terms, Functions, and Concepts  | MongoDB Aggregation Operators  |\n",
    "| ----------------------------------  |:-------------------------------|\n",
    "| WHERE                               | \\$match                        |\n",
    "| GROUP BY                            | \\$group                        |\n",
    "| HAVING                              | \\$match                        |\n",
    "| SELECT\t                          | \\$project                      |\n",
    "| ORDER BY\t                          | \\$sort                         |\n",
    "| LIMIT                               | \\$limit                        |\n",
    "| SUM()   \t                          | \\$sum                          |\n",
    "| COUNT()\t                          | \\$sum                          |\n",
    "| join\t                              | \\$lookup                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'records', u'system.indexes']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.earthwindfire.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'system.indexes']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete our records collection\n",
    "conn.earthwindfire.drop_collection(\"records\")\n",
    "conn.earthwindfire.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'earthwindfire', u'local', u'mydb']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'local', u'mydb']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the earthwindfire database\n",
    "conn.drop_database(\"earthwindfire\")\n",
    "conn.database_names()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
